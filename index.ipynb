{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Dynamics: Node Centrality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Think about your social network on , say, Facebook.There will be certain common individuals who perform certain important functions i.e. likes , shares and comments etc. Also, there could be some super connected individuals who are connected to many other people OR people who aggressively post to Facebook. These people could be helpful during say, certain information dissemination activity when required. Alternatively, if this were a disease contact network, identifying key individuals with a higher degree of contact would be useful in stopping the spread of diseases, a webpage on your site that is catching most attention etc.  How would one identify these nodes, having a central location in your network? . This is the question we try to answer with centrality measures. \n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Understand and explain network centrality and its importance in graph analysis\n",
    "* Understand and calculate Degree, Closeness, Betweenness and Eigenvector centrality measures\n",
    "* Describe the use case for several centrality measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Centrality \n",
    "\n",
    "The notion of centrality helps us identify Which nodes are most 'central' in a given network. Definition of 'central' varies by context/purpose of the analysis and situation. It could be based of number of connections or with a discrimination between incoming and outgoing connections from a node. A local measure for calculating centrality on these lines is the \"Degree\" of a node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Centrality \n",
    "\n",
    "The **degree** of a node is the number of other nodes to which it is connected. \n",
    "\n",
    "<img src=\"degree.jpg\" width=600>\n",
    "\n",
    "NetworkX's degree centrality is calculated by taking the degree of the node and dividing by `n-1` where where `n` is the number of nodes in `G`.\n",
    "\n",
    "$$ {C_D (u)} = \\frac{deg(u)}{{n-1}} $$\n",
    "\n",
    "__NOTE__: In directed graphs, both in-degree and out-degree centrality can be calculated and analyzed.\n",
    "\n",
    "\n",
    "Let's load our Grey's anatomy romatic encounters graph we created earlier and calculate this measure. \n",
    "\n",
    "```python\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Load GA graph and display \n",
    "GA = nx.read_gexf('ga_graph.gexf')\n",
    "plt.figure(3,figsize=(9,5)) \n",
    "nx.draw(GA, with_labels=True)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code here\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# load the graph for Grey's Anatomy\n",
    "plt.figure(3, figsize=(10, 8))\n",
    "GA = nx.read_gexf('ga_graph.gexf')\n",
    "nx.draw(GA, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the degree of our main character `Grey`.\n",
    "\n",
    "```python\n",
    "# Get the degree of a node\n",
    "GA.degree(\"grey\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "# the degree shows the nodes that are connected to the source\n",
    "GA.degree('grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that we have 4 connections to the node 'grey'. Likewise, we can find the degree of each cast member.\n",
    "\n",
    "```python\n",
    "# Get degree for whole network\n",
    "print(GA.degree())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lexi', 3), ('susan grey', 1), ('denny', 1), ('ben', 1), ('finn', 1), ('adele', 1), ('yang', 3), ('ellis grey', 2), ('arizona', 1), ('addison', 3), (\"o'malley\", 4), ('thatch grey', 2), ('altman', 2), ('tucker', 1), ('karev', 7), ('hank', 1), ('mrs. seabury', 1), ('owen', 2), ('kepner', 1), ('grey', 4), ('bailey', 2), ('olivia', 2), ('torres', 4), ('steve', 1), ('nancy', 1), ('colin', 1), ('derek', 2), ('izzie', 4), ('chief', 2), ('sloan', 5), ('avery', 1), ('preston', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "# to show the degrees for all nodes leave the parameter in .degree() blank\n",
    "print(GA.degree())\n",
    "# returns a list of tuples with the node and degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the top 5 nodes with high degree value\n",
    "```python\n",
    "# Here's the top 5 nodes\n",
    "sorted(GA.degree(), key=lambda x:x[1], reverse=True)[:5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('karev', 7), ('sloan', 5), (\"o'malley\", 4), ('grey', 4), ('torres', 4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "sorted(GA.degree(), key=lambda x:x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing this number is good start, it is also a good idea to normalize degree values between zero and one so that they can be more easily compared to one another, and that gives us degree centrality measure.\n",
    "\n",
    "For the **degree centrality** measure, the normalized interpretion works as below:  \n",
    "\n",
    "> _What percentage of nodes is this node connected to?_\n",
    "\n",
    "Or for our Grey's Anatomy example: \n",
    "\n",
    "> _What percentage of the cast has this character been romantically invovled with?_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the degree centrality for Grey using the formula above.\n",
    "\n",
    "\n",
    "```python\n",
    "# Degree for the 'Grey' node\n",
    "degree_grey = GA.degree(\"grey\")  # 4 romantic partners\n",
    "\n",
    "# Total number of nodes (excluding Grey) \n",
    "total_nodes_minus_grey = len(GA.nodes())-1  # 31 characters in the cast, excluding Grey\n",
    "\n",
    "# Degree centrality for Grey\n",
    "degree_centrality_grey = (degree_grey / total_nodes_minus_grey)\n",
    "print(\"Calculated degree centrality for Grey:\", degree_centrality_grey)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated degree centrality for Grey: 0.12903225806451613\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "# get the degree for grey\n",
    "degree_grey = GA.degree('grey')\n",
    "\n",
    "#get the total number of nodes\n",
    "total_nodes_minus_grey = len(GA.nodes()) - 1\n",
    "\n",
    "# calculate the degree of centrality for grey\n",
    "degree_centrality_grey = degree_grey / total_nodes_minus_grey\n",
    "\n",
    "print(f'Calculated degree centrality for Grey: {degree_centrality_grey}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use networkx's built in method to calculate this\n",
    "\n",
    "```python\n",
    "# Degree Centrality in networkx\n",
    "print(\"Networkx degree centrality for Grey:\", nx.degree_centrality(GA)[\"grey\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Networkx degree of centrality for Grey: 0.12903225806451613\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "# the networkx library has it's own way of calculating degrees of centrality with the degree_centrality() method\n",
    "# nx.degree_centrality returns a dictionary, pass the key to return a specific node\n",
    "nx_degree_centrality = nx.degree_centrality(GA)['grey']\n",
    "print(f'Networkx degree of centrality for Grey: {nx_degree_centrality}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our values match well. Let's now find the degree centrality for all characters.\n",
    "\n",
    "```python\n",
    "# Degree Centrality for all characters\n",
    "degree_centrality = nx.degree_centrality(GA)\n",
    "print(degree_centrality)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lexi': 0.0967741935483871, 'susan grey': 0.03225806451612903, 'denny': 0.03225806451612903, 'ben': 0.03225806451612903, 'finn': 0.03225806451612903, 'adele': 0.03225806451612903, 'yang': 0.0967741935483871, 'ellis grey': 0.06451612903225806, 'arizona': 0.03225806451612903, 'addison': 0.0967741935483871, \"o'malley\": 0.12903225806451613, 'thatch grey': 0.06451612903225806, 'altman': 0.06451612903225806, 'tucker': 0.03225806451612903, 'karev': 0.22580645161290322, 'hank': 0.03225806451612903, 'mrs. seabury': 0.03225806451612903, 'owen': 0.06451612903225806, 'kepner': 0.03225806451612903, 'grey': 0.12903225806451613, 'bailey': 0.06451612903225806, 'olivia': 0.06451612903225806, 'torres': 0.12903225806451613, 'steve': 0.03225806451612903, 'nancy': 0.03225806451612903, 'colin': 0.03225806451612903, 'derek': 0.06451612903225806, 'izzie': 0.12903225806451613, 'chief': 0.06451612903225806, 'sloan': 0.16129032258064516, 'avery': 0.03225806451612903, 'preston': 0.03225806451612903}\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "#the degree of centalityy can be calculated for all nodes\n",
    "GA_degrees_centrality = nx.degree_centrality(GA)\n",
    "print(GA_degrees_centrality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now identify top five characters from the cast with most encounters\n",
    "\n",
    "```python\n",
    "\n",
    "# Top 5. Percent of cast\n",
    "sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('karev', 0.22580645161290322),\n",
       " ('sloan', 0.16129032258064516),\n",
       " (\"o'malley\", 0.12903225806451613),\n",
       " ('grey', 0.12903225806451613),\n",
       " ('torres', 0.12903225806451613)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "sorted(GA_degrees_centrality.items(), key=lambda x:x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So same as the degree, only normalized. It is always a good idea to save the degree or any other centrality measures back to the graph as a node attribute for later analysis. \n",
    "\n",
    "```python\n",
    "# apply measurements back to Graph\n",
    "for k, v in degree_centrality.items():\n",
    "#     GA.add_node(k)\n",
    "    GA.node[k]['degree_centrality'] = v\n",
    "GA.node['karev']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'karev', 'degree_centrality': 0.22580645161290322}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "# A good practice is to save the measure of centrality back into the graph\n",
    "# Using a for loop, you can assign the measure of centrality to the graph\n",
    "for k, v in GA_degrees_centrality.items():\n",
    "    GA.node[k]['degree_centrality'] = v\n",
    "GA.node['karev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('lexi', 'susan grey', 'denny', 'ben', 'finn', 'adele', 'yang', 'ellis grey', 'arizona', 'addison', \"o'malley\", 'thatch grey', 'altman', 'tucker', 'karev', 'hank', 'mrs. seabury', 'owen', 'kepner', 'grey', 'bailey', 'olivia', 'torres', 'steve', 'nancy', 'colin', 'derek', 'izzie', 'chief', 'sloan', 'avery', 'preston'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GA.node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closeness Centrality\n",
    "Closeness Centrality measures how many \"hops\" a node would take to reach **every other node** in a network (taking the shortest path). It can be informally thought as 'average distance' to all other nodes. This \"Far-ness\" is then transformed into \"nearness\" as the reciprocal of farness.  That is, nearness = one divided by farness.  \"Nearness\" can be further standardized by norming against the minimum possible nearness for a graph of the same size and connection.\n",
    "\n",
    "<img src=\"close.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closeness is the reciporical of of the *average* value, which normalizes the value in a 0 to 1 range. \n",
    "\n",
    "$$ C_C (u) = \\frac{n - 1}{\\sum_{v=1}^{n-1} d(v, u)} $$\n",
    "\n",
    "If you again take the reciporical of this equation, you'll find the *average* distance to all other nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Why should we care about closeness centrality?__\n",
    "\n",
    "> Degree centrality measures might be criticized because they only take into account the immediate ties that an node has, or the ties of the nodes' neighbors, rather than indirect ties to all others nodes. A node might be tied to a large number of others, but those others might be rather disconnected from the network. In a case like this, the node could be quite central, but only in a local neighborhood. [[Source](http://www.faculty.ucr.edu/~hanneman/nettext/C10_Centrality.html#Closeness)]\n",
    "\n",
    "In our example, closeness centrality can help us understand a number of phenomenon. For example we can check which which characters have the greatest potential to spread an infectous disease or STD across the cast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Shortest Path \n",
    "Let's calculate the closeness centrality for Grey. First we'll start by getting the shortest paths between Grey and all other characters.\n",
    "\n",
    "```python\n",
    "# Shortest path between Grey and other characters\n",
    "grey_shortest_path = dict(nx.shortest_path_length(GA))['grey']\n",
    "grey_shortest_path\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grey': 0,\n",
       " 'finn': 1,\n",
       " \"o'malley\": 1,\n",
       " 'steve': 1,\n",
       " 'derek': 1,\n",
       " 'izzie': 2,\n",
       " 'olivia': 2,\n",
       " 'torres': 2,\n",
       " 'addison': 2,\n",
       " 'denny': 3,\n",
       " 'karev': 3,\n",
       " 'hank': 3,\n",
       " 'arizona': 3,\n",
       " 'sloan': 3,\n",
       " 'lexi': 4,\n",
       " 'mrs. seabury': 4,\n",
       " 'kepner': 4,\n",
       " 'altman': 4,\n",
       " 'nancy': 4,\n",
       " 'avery': 5,\n",
       " 'owen': 5,\n",
       " 'yang': 6,\n",
       " 'colin': 7,\n",
       " 'preston': 7}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "# Closeness measure how many hops it takes to go from the source node to another node\n",
    "# to get the calculate the closeness, use the .shortest_path_length() method.\n",
    "grey_shortest_path = dict(nx.shortest_path_length(GA))['grey']\n",
    "grey_shortest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go ahead and caluclate the closeness centrality for Grey using the formula above\n",
    "\n",
    "```python\n",
    "# Sum of the shortest paths to all other characters\n",
    "grey_sum_shortest_path = sum(grey_shortest_path.values())  # 77\n",
    "\n",
    "# Closeness centrality for Grey\n",
    "closeness_centrality_grey = (total_nodes_minus_grey / grey_sum_shortest_path)\n",
    "print(\"Calculated closeness centrality for Grey:\", closeness_centrality_grey)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Closeness centrality for Grey: 0.4025974025974026\n"
     ]
    }
   ],
   "source": [
    "# sum of shortest paths to all other characters\n",
    "grey_sum_shortest_path = sum(grey_shortest_path.values())\n",
    "\n",
    "closeness_centrality_grey = total_nodes_minus_grey / grey_sum_shortest_path\n",
    "print(f'Calculated Closeness centrality for Grey: {closeness_centrality_grey}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "# To calculate the shortest path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring in networkx's built in method to calculate , and see if we calculated it right \n",
    "\n",
    "```python\n",
    "# Closeness centrality with networkx\n",
    "print(\"Networkx closeness centrality for Grey:\", nx.closeness_centrality(GA)[\"grey\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Networkx closeness centrality for Grey: 0.2216170925848345\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "# networkx has it's method for calculating shortest path\n",
    "# use nx.closeness_centrality() method\n",
    "nx_closeness_grey = nx.closeness_centrality(GA)['grey']\n",
    "print(f'Networkx closeness centrality for Grey: {nx_closeness_grey}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"what.jpg\" width=300>\n",
    "\n",
    "These dont match. What really happened ?\n",
    "\n",
    "This mismatch is because of the character relationship graph is not fully connected. (i.e., there are groups of characters that do not have relationships with one another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct for this, we will use the number of nodes in the `Grey` subgraph instead of the total number of nodes to calculated degree centrality.  Additionally, we'll normalized to `(n-1)/(|G|-1)` where `n` is the number of nodes in the connected part of graph containing the node.\n",
    "\n",
    "```python\n",
    "# Number of nodes in Grey subgraph, excluding Grey\n",
    "total_nodes_minus_grey_sub = len(grey_shortest_path)-1  \n",
    "\n",
    "# Closeness centrality for Grey (unnormalized)\n",
    "closeness_centrality_grey = (total_nodes_minus_grey_sub / grey_sum_shortest_path) \n",
    "print(\"Calculated closeness centrality for Grey (Un-normalized):\", closeness_centrality_grey)\n",
    "\n",
    "# Closeness centrality for Grey (normalized)\n",
    "closeness_centrality_grey_normalized = closeness_centrality_grey * (total_nodes_minus_grey_sub/total_nodes_minus_grey)\n",
    "print(\"Calculated closeness centrality for Grey (normalized):\", closeness_centrality_grey_normalized)\n",
    "\n",
    "# In networkx\n",
    "print(\"Networkx closeness centrality for Grey:\", nx.closeness_centrality(GA)[\"grey\"])\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 6, 7, 7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(nx.shortest_path_length(GA))['grey'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated closeness centrality for Grey (Un-normalized): 0.2987012987012987)\n",
      "Calculated closeness centrality for Grey (Normalized): 57.12903225806452\n",
      "Calculated closeness centrality NX method: 0.2216170925848345\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "# The formula for calculating normalized closeness is (n-1) / (|G| - 1)\n",
    "# Where n, is the sum of values in shortest path\n",
    "# and G, is the sume of centality - 1\n",
    "\n",
    "# number of nodes in grey subgraph\n",
    "sum_closeness_centrality = sum(dict(nx.shortest_path_length(GA))['grey'].values())\n",
    "\n",
    "# number of nodes in Grey subgraph, excluding Grey\n",
    "total_nodes_minus_grey_sub = len(grey_shortest_path)-1 \n",
    "\n",
    "# closenss centrality (unnormalized)\n",
    "closeness_centrality_grey_unnorm = total_nodes_minus_grey_sub / sum_closeness_centrality\n",
    "print(f'Calculated closeness centrality for Grey (Un-normalized): {closeness_centrality_grey_unnorm})')\n",
    "\n",
    "# closeness centrality (normalized)\n",
    "closeness_centrality_grey_norm = sum_closeness_centrality * (total_nodes_minus_grey_sub / total_nodes_minus_grey)\n",
    "print(f'Calculated closeness centrality for Grey (Normalized): {closeness_centrality_grey_norm}')\n",
    "\n",
    "# closeness centrality using nx.closeness_centrality() method\n",
    "print(f'Calculated closeness centrality NX method: {nx.closeness_centrality(GA)[\"grey\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot on, so now we have the same result as networkx. Let's find the closeness centrality for all characters and pick top 5.\n",
    "\n",
    "```python\n",
    "# Calculate closeness for all cast and pick top 5\n",
    "sorted(nx.closeness_centrality(GA).items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('torres', 0.29937747594793435),\n",
       " ('addison', 0.2892290869327502),\n",
       " ('karev', 0.2892290869327502),\n",
       " ('sloan', 0.2892290869327502),\n",
       " (\"o'malley\", 0.2708653353814644)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "sorted(nx.closeness_centrality(GA).items(), key=lambda x: x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the sequence is slightly different than that we saw in degree centrality, as now are considering subgraphs and connectedness of the graph. \n",
    "\n",
    "As before save this measure back to the graph.\n",
    "\n",
    "```python\n",
    "# apply measurements back to Graph\n",
    "for k, v in closeness_centrality.items():\n",
    "#     GA.add_node(k)\n",
    "    GA.node[k]['closeness_centrality'] = v\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "for k, v in nx.closeness_centrality(GA).items():\n",
    "    GA.node[k]['closeness_centrality'] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure the nearness and/or farness from this attribute as we explained earlier.\n",
    "\n",
    "```python\n",
    "# average distance of torres:\n",
    "1 / closeness_centrality['torres']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.340264650283554"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "1 / nx.closeness_centrality(GA)['torres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweeness Centrality\n",
    "\n",
    "Betweenness centrality measures the **number of times a node acts as a bridge along the shortest path between two other nodes**.  Here nodes that have a high probability to occur on a randomly chosen shortest path between two randomly chosen nodes have a **high betweenness**.\n",
    "\n",
    "$$ C_B(v) =\\sum_{s,t \\in V} \\frac{\\sigma(s, t|v)}{\\sigma(s, t)} $$\n",
    "\n",
    "where ${\\sigma(s, t)}$ is total number of shortest paths from node ${s}$ to node ${t}$ and ${\\sigma(s, t|v)}$ is the number of those paths that pass through ${v}$ as shown in the example below:\n",
    "\n",
    "<img src=\"between.jpg\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Why is betweeness centrality important?__\n",
    "\n",
    "> In order to create influence in a network by sending information, or exchanging transactions, we usually go through an intermediary. For example, let's suppose you want to convince the board to invest in a new product. You must forward my request through your department head, a Manager, and an executive. These people would have a huge influence on weather your request gets acccpted, rejected or delayed. This gives the people who lie \"between\" you and the chair, power with respect to you. \n",
    "\n",
    "While this measure is not relevant to Grey's anatomy dataset, let's just see how to calculate it with an imaginary scenario.\n",
    "\n",
    "#### To engage with a new romantic partner, a cast member needs permission from at least one of their former partners and they can only send your request through existing partners (eew .. but it will help us understand betweenness). \n",
    "\n",
    "Betweeness centrality can tell us which actors had the most effective influence on the requests made by a cast member to another cast member in the network - in a random fashion. \n",
    "\n",
    "\n",
    "```python\n",
    "# Calculate the betweenness centrality \n",
    "betweeness_centrality = nx.betweenness_centrality(GA)\n",
    "betweeness_centrality\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lexi': 0.07741935483870968, 'susan grey': 0.0, 'denny': 0.0, 'ben': 0.0, 'finn': 0.0, 'adele': 0.0, 'yang': 0.09247311827956989, 'ellis grey': 0.008602150537634409, 'arizona': 0.0, 'addison': 0.09480286738351255, \"o'malley\": 0.11702508960573477, 'thatch grey': 0.0064516129032258064, 'altman': 0.16344086021505377, 'tucker': 0.0, 'karev': 0.20487455197132617, 'hank': 0.0, 'mrs. seabury': 0.0, 'owen': 0.12903225806451613, 'kepner': 0.0, 'grey': 0.10078853046594982, 'bailey': 0.002150537634408602, 'olivia': 0.01064516129032258, 'torres': 0.14440860215053763, 'steve': 0.0, 'nancy': 0.0, 'colin': 0.0, 'derek': 0.03860215053763442, 'izzie': 0.10311827956989245, 'chief': 0.0064516129032258064, 'sloan': 0.24810035842293907, 'avery': 0.0, 'preston': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "# Calculate betweenness centrality\n",
    "# Use the nx.betweenness_centrality() method\n",
    "betweeness_centrality = nx.betweenness_centrality(GA)\n",
    "print(betweeness_centrality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As earlier , we can sort these values to get our top 5. \n",
    "\n",
    "```python\n",
    "# get top 5 wrt betweenness\n",
    "sorted(betweeness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sloan', 0.24810035842293907),\n",
       " ('karev', 0.20487455197132617),\n",
       " ('altman', 0.16344086021505377),\n",
       " ('torres', 0.14440860215053763),\n",
       " ('owen', 0.12903225806451613)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "sorted(betweeness_centrality.items(), key=lambda x:x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a standard pratice we can save these values back to the graph\n",
    "\n",
    "```python\n",
    "# apply measurements back to Graph\n",
    "for k, v in betweeness_centrality.items():\n",
    "#     GA.add_node(k)\n",
    "    GA.node[k]['betweeness_centrality'] = v\n",
    "\n",
    "# Check the graph so far \n",
    "GA.node['karev']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'karev',\n",
       " 'degree_centrality': 0.22580645161290322,\n",
       " 'closeness_centrality': 0.2892290869327502,\n",
       " 'betweeness_centrality': 0.20487455197132617}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "for k, v in betweeness_centrality.items():\n",
    "#     GA.add_node(k)\n",
    "    GA.node[k]['betweeness_centrality'] = v\n",
    "\n",
    "# Check the graph so far \n",
    "GA.node['karev']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvector Centrality\n",
    "\n",
    "A node is high in eigenvector centrality if it is connected to many other nodes who are themselves well connected. Eigenvector centrality for each node is simply calculated as the proportional eigenvector values of the eigenvector with the largest eigenvalue. Following image shows you a quick comparison between degree and eigenvector centrality. Here node A is connected to more well connected nodes than B and hence shows a higher Eigenvector centrality, although the degree of B is higher than A. \n",
    "\n",
    "<img src=\"eigen.png\" width=300>\n",
    "\n",
    "[Visit here to get a deep dive in the underlying maths](https://www.geeksforgeeks.org/eigenvector-centrality-centrality-measure/), which involves some matrix algebra. We shall use networkx's built in method to calculate this for now. \n",
    "\n",
    "```python\n",
    "# Calculate eigenvector centrality for GA\n",
    "eigenvector_centrality = nx.eigenvector_centrality_numpy(GA)\n",
    "eigenvector_centrality\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lexi': 0.2642455341015445,\n",
       " 'susan grey': -1.215113814834235e-17,\n",
       " 'denny': 0.08320301854301705,\n",
       " 'ben': 1.3800518718021882e-16,\n",
       " 'finn': 0.044220171351811895,\n",
       " 'adele': 1.6784293834574418e-17,\n",
       " 'yang': 0.012041089122459393,\n",
       " 'ellis grey': 1.9193684119236167e-18,\n",
       " 'arizona': 0.10564201543690802,\n",
       " 'addison': 0.2784013959452949,\n",
       " \"o'malley\": 0.30201197095059656,\n",
       " 'thatch grey': -3.209532105241754e-17,\n",
       " 'altman': 0.10442628192357353,\n",
       " 'tucker': 1.8883964388113192e-16,\n",
       " 'karev': 0.5027687871890409,\n",
       " 'hank': 0.08320301854301719,\n",
       " 'mrs. seabury': 0.1471588769531373,\n",
       " 'owen': 0.0340896411263779,\n",
       " 'kepner': 0.14715887695313737,\n",
       " 'grey': 0.1510783608855744,\n",
       " 'bailey': 2.7638447342007303e-16,\n",
       " 'olivia': 0.2355568515369943,\n",
       " 'torres': 0.3609262932492619,\n",
       " 'steve': 0.044220171351811874,\n",
       " 'nancy': 0.09444834886225358,\n",
       " 'colin': 0.0035243897348137382,\n",
       " 'derek': 0.12570740328311916,\n",
       " 'izzie': 0.2842633865482769,\n",
       " 'chief': 6.747053657689562e-17,\n",
       " 'sloan': 0.32268309457542527,\n",
       " 'avery': 0.07734385472828512,\n",
       " 'preston': 0.003524389734813741}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "eigenvector_centrality = nx.eigenvector_centrality_numpy(GA)\n",
    "eigenvector_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Let's just save this measure back to graph as earlier.\n",
    "\n",
    "```python\n",
    "# apply measurements back to Graph\n",
    "for k, v in eigenvector_centrality.items():\n",
    "    GA.node[k]['eigenvector_centrallity'] = v\n",
    "# Check the graph so far \n",
    "GA.node['karev'] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'karev',\n",
       " 'degree_centrality': 0.22580645161290322,\n",
       " 'closeness_centrality': 0.2892290869327502,\n",
       " 'betweeness_centrality': 0.20487455197132617,\n",
       " 'eigenvector_centrallity': 0.5027687871890409}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here  \n",
    "for k, v in eigenvector_centrality.items():\n",
    "    GA.node[k]['eigenvector_centrallity'] = v\n",
    "# Check the graph so far \n",
    "GA.node['karev'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check this measure with respect to a certain character in the graph by scaling values. Let's find the character with highest eigenvector centrality and scale the others based on this value.  \n",
    "\n",
    "\n",
    "```python\n",
    "# Calculate the character with highest eigenvector value\n",
    "max_value = max(eigenvector_centrality.items(), key=lambda x: x[1])\n",
    "\n",
    "# Scale by the most central character (karev) and return top 5 \n",
    "ec_scaled = {}\n",
    "for k in eigenvector_centrality.keys():\n",
    "    ec_scaled[k] = eigenvector_centrality[k] / max_value[1]\n",
    "sorted(ec_scaled.items(), key=lambda x:x[1], reverse=True)[0:5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('karev', 1.0),\n",
       " ('torres', 0.7178772876239704),\n",
       " ('sloan', 0.6418121068722917),\n",
       " (\"o'malley\", 0.6006975346244796),\n",
       " ('izzie', 0.5653958515157265)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "# get the max value eignvector\n",
    "max_value = max(eigenvector_centrality.items(), key=lambda x:x[1])\n",
    "\n",
    "# Scale most central character and return top 5\n",
    "ec_scaled = {}\n",
    "for k in eigenvector_centrality.keys():\n",
    "    ec_scaled[k] = eigenvector_centrality[k] / max_value[1]\n",
    "sorted(ec_scaled.items(), key=lambda x: x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- https://cs.brynmawr.edu/Courses/cs380/spring2013/section02/slides/05_Centrality.pdf\n",
    "- http://www.faculty.ucr.edu/~hanneman/nettext/C10_Centrality.html#paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "<img src=\"cen.png\" width = 600>\n",
    "\n",
    "In this lesson, we looked at a number of centrality measures with calculations and how to measure tthem in networkx. We also learned to store these as network node attributes which can be used for later analysis. Next we shall see a problem centred around the issue of centrality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
